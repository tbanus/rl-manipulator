{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVsHSxOMhxps",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# !pip install mujoco\n",
        "# !pip install mujoco_mjx\n",
        "# !pip install brax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5f4w3Kq2X14",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "#@title Import packages for plotting and creating graphics\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "from typing import Callable, NamedTuple, Optional, Union, List\n",
        "\n",
        "# Graphics and plotting.\n",
        "print(\"git test\")\n",
        "print('Installing mediapy:')\n",
        "# !command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "# !pip install -q mediapy\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# More legible printing from numpy.\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbZxYDxzoz5R",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "#@title Check if MuJoCo installation was successful\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
        "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
        "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
        "os.environ['XLA_FLAGS'] = xla_flags\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
        "\n",
        "print('Installation successful.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFOwnK6ph7cJ",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import functools\n",
        "from IPython.display import HTML\n",
        "import jax\n",
        "from jax import numpy as jp\n",
        "import numpy as np\n",
        "from typing import Any, Dict, Sequence, Tuple, Union\n",
        "\n",
        "from brax import base\n",
        "from brax import envs\n",
        "from brax import math\n",
        "from brax.base import Base, Motion, Transform\n",
        "from brax.envs.base import Env, PipelineEnv, State\n",
        "from brax.mjx.base import State as MjxState\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from brax.training.agents.ppo import networks as ppo_networks\n",
        "from brax.io import html, mjcf, model\n",
        "\n",
        "from etils import epath\n",
        "from flax import struct\n",
        "from matplotlib import pyplot as plt\n",
        "import mediapy as media\n",
        "from ml_collections import config_dict\n",
        "import mujoco\n",
        "from mujoco import mjx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34iVTavRiB_v",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "mj_model = mujoco.MjModel.from_xml_path('unitree_z1/scene.xml')\n",
        "mj_data = mujoco.MjData(mj_model)\n",
        "renderer = mujoco.Renderer(mj_model)\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
        "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".75\"\n",
        "# os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "rHp19frlRLa9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".75\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "Qwvo_EMnRLa9"
      },
      "outputs": [],
      "source": [
        "# class TrainManipulator():\n",
        "import mujoco\n",
        "from mujoco import mjx\n",
        "import jax\n",
        "\n",
        "    # def __init(self):\n",
        "mj_model = mujoco.MjModel.from_xml_path('unitree_z1/scene.xml')\n",
        "mj_model.opt.solver = mujoco.mjtSolver.mjSOL_CG\n",
        "mj_model.opt.iterations = 6\n",
        "mj_model.opt.ls_iterations = 6\n",
        "mjx_model = mjx.device_put(mj_model)\n",
        "\n",
        "@jax.vmap\n",
        "def batched_step(vel):\n",
        "    mjx_data = mjx.make_data(mjx_model)\n",
        "    qvel = mjx_data.qvel.at[0].set(vel)\n",
        "    mjx_data = mjx_data.replace(qvel=qvel)\n",
        "    pos = mjx.step(mjx_model, mjx_data).qpos[0]\n",
        "    return pos\n",
        "\n",
        "vel = jax.numpy.arange(0.0, 1000.0, 0.001)\n",
        "pos = jax.jit(batched_step)(vel)\n",
        "print(\"total step size\", len(vel))\n",
        "print(pos)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bqHd-xjmO11",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "#@title Sim Env\n",
        "\n",
        "class Manipulator(PipelineEnv):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      forward_reward_weight=1.25,\n",
        "      ctrl_cost_weight=0.1,\n",
        "      healthy_reward=5.0,\n",
        "      terminate_when_unhealthy=True,\n",
        "      healthy_z_range=(1.0, 2.0),\n",
        "      reset_noise_scale=1e-2,\n",
        "      exclude_current_positions_from_observation=True,\n",
        "      **kwargs,\n",
        "  ):\n",
        "\n",
        "    mj_model = mujoco.MjModel.from_xml_path('unitree_z1/scene.xml')\n",
        "    mj_model.opt.solver = mujoco.mjtSolver.mjSOL_CG\n",
        "    mj_model.opt.iterations = 6\n",
        "    mj_model.opt.ls_iterations = 6\n",
        "\n",
        "    sys = mjcf.load_model(mj_model)\n",
        "    self.target_pos=[0.5, 0.0, 0.05]\n",
        "    physics_steps_per_control_step = 5\n",
        "    kwargs['n_frames'] = kwargs.get(\n",
        "        'n_frames', physics_steps_per_control_step)\n",
        "    kwargs['backend'] = 'mjx'\n",
        "\n",
        "    super().__init__(sys, **kwargs)\n",
        "\n",
        "    self._forward_reward_weight = forward_reward_weight\n",
        "    self._ctrl_cost_weight = ctrl_cost_weight\n",
        "    self._healthy_reward = healthy_reward\n",
        "    self._terminate_when_unhealthy = terminate_when_unhealthy\n",
        "    self._healthy_z_range = healthy_z_range\n",
        "    self._reset_noise_scale = reset_noise_scale\n",
        "    self._exclude_current_positions_from_observation = (\n",
        "        exclude_current_positions_from_observation\n",
        "    )\n",
        "\n",
        "  def reset(self, rng: jp.ndarray) -> State:\n",
        "    \"\"\"Resets the environment to an initial state.\"\"\"\n",
        "    rng, rng1, rng2 = jax.random.split(rng, 3)\n",
        "\n",
        "    low, hi = -self._reset_noise_scale, self._reset_noise_scale\n",
        "    qpos = self.sys.qpos0 + jax.random.uniform(\n",
        "        rng1, (self.sys.nq,), minval=low, maxval=hi\n",
        "    )\n",
        "    qvel = jax.random.uniform(\n",
        "        rng2, (self.sys.nv,), minval=low, maxval=hi\n",
        "    )\n",
        "\n",
        "    data = self.pipeline_init(qpos, qvel)\n",
        "\n",
        "    obs = self._get_obs(data, jp.zeros(self.sys.nu))\n",
        "    reward, done, zero = jp.zeros(3)\n",
        "    metrics = {\n",
        "        'reward_hand_pos': zero,\n",
        "        'cost_torque': zero,\n",
        "        'cost_base_disturbance': zero,\n",
        "        'j1_pos': zero,\n",
        "        'j2_pos': zero,\n",
        "        'j3_pos': zero,\n",
        "        'j4_pos': zero,\n",
        "        'j5_pos': zero,\n",
        "        'j6_pos': zero,\n",
        "        'load_pos_x': zero,\n",
        "        'load_pos_y': zero,\n",
        "        'load_pos_z': zero\n",
        "\n",
        "\n",
        "    }\n",
        "    return State(data, obs, reward, done, metrics)\n",
        "\n",
        "  def step(self, state: State, action: jp.ndarray) -> State:\n",
        "    \"\"\"Run 1 timestep of the simulation.\"\"\"\n",
        "    data0 = state.pipeline_state\n",
        "    print(state.pipeline_state)\n",
        "    data = self.pipeline_step(data0, action)\n",
        "\n",
        "    # com_before = data0.subtree_com[1]\n",
        "    # com_after = data.subtree_com[1]\n",
        "    # velocity = (com_after - com_before) / self.dt\n",
        "\n",
        "    j1_pos=data.qpos[0]\n",
        "    j2_pos=data.qpos[1]\n",
        "    j3_pos=data.qpos[2]\n",
        "    j4_pos=data.qpos[3]\n",
        "    j5_pos=data.qpos[4]\n",
        "    j6_pos=data.qpos[5]\n",
        "    reward_hand_pos=0.0\n",
        "    cost_torque=0.0\n",
        "    cost_base_disturbance=0.0\n",
        "    load_pos_x=data.qpos[6]\n",
        "    load_pos_y=data.qpos[7]\n",
        "    load_pos_z=data.qpos[8]\n",
        "    # if self._terminate_when_unhealthy:\n",
        "    #   healthy_reward = self._healthy_reward\n",
        "    # else:\n",
        "    #   healthy_reward = self._healthy_reward\n",
        "\n",
        "    # ctrl_cost = self._ctrl_cost_weight * jp.sum(jp.square(action))\n",
        "    reward_hand_pos = self._forward_reward_weight *(  (load_pos_x-self.target_pos[0])**2+(load_pos_y-self.target_pos[1])**2+(load_pos_z-self.target_pos[2])**2)\n",
        "    ctrl_cost =0.0\n",
        "    for i in range(0,len(action)):\n",
        "       ctrl_cost+=action[i]**2\n",
        "    obs = self._get_obs(data, action)\n",
        "    reward = reward_hand_pos  - ctrl_cost\n",
        "    # load_position =  state.select.,\n",
        "    done = 0.0\n",
        "    print(\"self.target_pos[0]\",self.target_pos[0])\n",
        "    print(\"load_pos_y\", load_pos_y)\n",
        "    print(\"all\", ((load_pos_x-self.target_pos[0])**2+(load_pos_y-self.target_pos[1])**2+(load_pos_z-self.target_pos[2])**2))\n",
        "    # if ( (load_pos_x-self.target_pos[0])**2+(load_pos_y-self.target_pos[1])**2+(load_pos_z-self.target_pos[2])**2)<0.01:\n",
        "    #   done=1\n",
        "    # done = 1.0  else 0.0\n",
        "    state.metrics.update(\n",
        "        reward_hand_pos=reward_hand_pos,\n",
        "        cost_torque=cost_torque,\n",
        "        cost_base_disturbance=-cost_base_disturbance,\n",
        "        j1_pos=j1_pos,\n",
        "        j2_pos=j2_pos,\n",
        "        j3_pos=j3_pos,\n",
        "        j4_pos=j4_pos,\n",
        "        j5_pos=j5_pos,\n",
        "        j6_pos=j6_pos,\n",
        "        load_pos_x=load_pos_x,\n",
        "        load_pos_y=load_pos_y,\n",
        "        load_pos_z=load_pos_z,\n",
        "    )\n",
        "\n",
        "    return state.replace(\n",
        "        pipeline_state=data, obs=obs, reward=reward, done=done\n",
        "    )\n",
        "\n",
        "  def _get_obs(\n",
        "      self, data: mjx.Data, action: jp.ndarray\n",
        "  ) -> jp.ndarray:\n",
        "    \"\"\"Observes body position, velocities, and angles.\"\"\"\n",
        "    position = data.qpos\n",
        "    # if self._exclude_current_positions_from_observation:\n",
        "    #   position = position[2:]\n",
        "\n",
        "    # external_contact_forces are excluded\n",
        "    return jp.concatenate([\n",
        "        position,\n",
        "        data.qvel,\n",
        "        data.cinert[1:].ravel(),\n",
        "        data.cvel[1:].ravel(),\n",
        "        data.qfrc_actuator,\n",
        "    ])\n",
        "\n",
        "\n",
        "envs.register_environment('manipulator', Manipulator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1K6IznI2y83"
      },
      "source": [
        "## Visualize a Rollout\n",
        "\n",
        "Let's instantiate the environment and visualize a short rollout.\n",
        "\n",
        "NOTE: Since episodes terminates early if the torso is below the healthy z-range, the only relevant contacts for this task are between the feet and the plane. We turn off other contacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhKLFK54C1CH",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# instanself.target_pos[0]tiate the environment\n",
        "env_name = 'manipulator'\n",
        "env = envs.get_environment(env_name)\n",
        "\n",
        "# define the jit reset/step functions\n",
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph8u-v2Q2xLS",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# initialize the state\n",
        "state = jit_reset(jax.random.PRNGKey(0))\n",
        "rollout = [state.pipeline_state]\n",
        "\n",
        "# grab a trajectory\n",
        "for i in range(30):\n",
        "  ctrl = -0.1 * jp.ones(env.sys.nu)\n",
        "  state = jit_step(state, ctrl)\n",
        "  rollout.append(state.pipeline_state)\n",
        "\n",
        "media.show_video(env.render(rollout, camera='side'), fps=1.0 / env.dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQDG6NQ1CbZD"
      },
      "source": [
        "## Train Policy\n",
        "\n",
        "Let's now train a policy with PPO to make the sim run forwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLiddQYPApBw",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "train_fn = functools.partial(\n",
        "    ppo.train, num_timesteps=30_000, num_evals=5, reward_scaling=0.1,\n",
        "    episode_length=1000, normalize_observations=True, action_repeat=1,\n",
        "    unroll_length=10, num_minibatches=32, num_updates_per_batch=8,\n",
        "    discounting=0.97, learning_rate=3e-4, entropy_cost=1e-3, num_envs=2048,\n",
        "    batch_size=1024, seed=0)\n",
        "\n",
        "\n",
        "x_data = []\n",
        "y_data = []\n",
        "ydataerr = []\n",
        "times = [datetime.now()]\n",
        "\n",
        "max_y, min_y = 13000, 0\n",
        "def progress(num_steps, metrics):\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics['eval/episode_reward'])\n",
        "  ydataerr.append(metrics['eval/episode_reward_std'])\n",
        "\n",
        "  plt.xlim([0, train_fn.keywords['num_timesteps'] * 1.25])\n",
        "  plt.ylim([min_y, max_y])\n",
        "\n",
        "  plt.xlabel('# environment steps')\n",
        "  plt.ylabel('reward per episode')\n",
        "  plt.title(f'y={y_data[-1]:.3f}')\n",
        "\n",
        "  plt.errorbar(\n",
        "      x_data, y_data, yerr=ydataerr)\n",
        "  plt.show()\n",
        "\n",
        "make_inference_fn, params, _= train_fn(environment=env, progress_fn=progress)\n",
        "\n",
        "print(f'time to jit: {times[1] - times[0]}')\n",
        "print(f'time to train: {times[-1] - times[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYIch0HEApBx"
      },
      "source": [
        "<!-- ## Save and Load Policy -->\n",
        "\n",
        "We can save and load the policy using the brax model API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8gI6qH6ApBx"
      },
      "outputs": [],
      "source": [
        "#@title Save Model\n",
        "model_path = '/tmp/mjx_brax_policy'\n",
        "model.save_params(model_path, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4reaWgxApBx"
      },
      "outputs": [],
      "source": [
        "#@title Load Model and Define Inference Function\n",
        "params = model.load_params(model_path)\n",
        "\n",
        "inference_fn = make_inference_fn(params)\n",
        "jit_inference_fn = jax.jit(inference_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpUgnXrsqACU"
      },
      "outputs": [],
      "source": [
        "#@title Load Model and Define Inference Function\n",
        "params = model.load_params(model_path)\n",
        "\n",
        "inference_fn = make_inference_fn(params)\n",
        "jit_inference_fn = jax.jit(inference_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G357XIfApBy"
      },
      "source": [
        "## Visualize Policy\n",
        "\n",
        "Finally we can visualize the policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osYasMw4ApBy"
      },
      "outputs": [],
      "source": [
        "eval_env = envs.get_environment(env_name)\n",
        "\n",
        "jit_reset = jax.jit(eval_env.reset)\n",
        "jit_step = jax.jit(eval_env.step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-UhypudApBy"
      },
      "outputs": [],
      "source": [
        "# initialize the state\n",
        "rng = jax.random.PRNGKey(0)\n",
        "state = jit_reset(rng)\n",
        "rollout = [state.pipeline_state]\n",
        "\n",
        "# grab a trajectory\n",
        "n_steps = 500\n",
        "render_every = 2\n",
        "\n",
        "for i in range(n_steps):\n",
        "  act_rng, rng = jax.random.split(rng)\n",
        "  ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "  state = jit_step(state, ctrl)\n",
        "  rollout.append(state.pipeline_state)\n",
        "\n",
        "  if state.done:\n",
        "    break\n",
        "\n",
        "media.show_video(env.render(rollout[::render_every], camera='side'), fps=1.0 / env.dt / render_every)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR-heox6LARK"
      },
      "source": [
        "# MJX Policy in MuJoCo\n",
        "\n",
        "We can also perform the physics step using the original MuJoCo python bindings to show that the policy trained in MJX works in MuJoCo."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}